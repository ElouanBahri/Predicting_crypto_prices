from typing import Union

import numpy as np
import pandas as pd
import tensorflow as tf


def change_X_data_1(X: pd.DataFrame) -> pd.DataFrame:
    X["trade"] = X["trade"].map({False: 0, True: 1})
    X["action"] = X["action"].map({"A": 0, "D": 1, "U": 2})
    X["side"] = X["side"].map({"A": 1, "B": 0})

    X["bid_size"] = np.log(X["bid_size"] + 1)
    X["ask_size"] = np.log(X["ask_size"] + 1)

    X["price"] = X["price"] * 10
    X["bid"] = X["bid"] * 100
    X["ask"] = X["ask"] * 100

    X = X.sort_values(by="obs_id").reset_index(drop=True)
    df_grouped = X.groupby("obs_id").mean().reset_index()

    return df_grouped


def change_X_data_2(X: pd.DataFrame) -> pd.DataFrame:
    X["trade"] = X["trade"].map({False: 0, True: 1})
    X["action"] = X["action"].map({"A": 0, "D": 1, "U": 2})
    X["side"] = X["side"].map({"A": 1, "B": 0})

    X["bid_size"] = np.log(X["bid_size"] + 1)
    X["ask_size"] = np.log(X["ask_size"] + 1)

    X["price"] = X["price"] * 10
    X["bid"] = X["bid"] * 100
    X["ask"] = X["ask"] * 100

    tensor_list = []

    # Group by 'obs_id'
    for obs_id, group in X.groupby("obs_id"):
        # Drop 'obs_id' column if it's not needed
        features = group.drop(columns=["obs_id"])

        matrix = np.array(features.values, dtype=np.float32)

        # Append the Tensor to the tensor list
        tensor_list.append(matrix)

    df = pd.DataFrame({"column 1": tensor_list})

    return df


def change_y_data(y: pd.DataFrame) -> pd.DataFrame:
    n = 100

    data_duplicated = pd.concat([y] * n, ignore_index=True)

    data_duplicated = data_duplicated.sort_values(by="obs_id").reset_index(drop=True)

    data_duplicated = data_duplicated.drop(columns=["obs_id"])

    return data_duplicated


def create_y_test_file(
    x_test: np.ndarray, model: Union[tf.keras.Model, any]
) -> pd.DataFrame:
    predictions = model.predict(x_test)  # Replace x_test with your input data

    predictions = np.argmax(predictions, axis=1)
    # Create a DataFrame with a single column for the predictions
    df_results = pd.DataFrame(predictions, columns=["eqt_code_cat"])

    df_results["obs_id"] = range(len(df_results))

    new_order = ["obs_id", "eqt_code_cat"]

    df_results = df_results[new_order]

    return df_results


def preprocees_order_book_data(df: pd.DataFrame) -> pd.DataFrame:
    df["mid_price"] = (df["bid"] + df["ask"]) / 2
    df["bid_ask_spread"] = df["ask"] - df["bid"]
    df["price_diff_bid"] = df["price"] - df["bid"]
    df["price_diff_ask"] = df["ask"] - df["price"]
    df["bid_ask_imbalance"] = (df["bid_size"] - df["ask_size"]) / (
        df["bid_size"] + df["ask_size"]
    )
    df["cumulative_flux"] = df.groupby("obs_id")["flux"].cumsum()

    # Rolling volatility of mid_price within each sequence
    df["volatility_mid_price"] = df.groupby("obs_id")["mid_price"].transform(
        lambda x: x.rolling(window=10).std()
    )

    # Replace the Nan value generated by the rolling window
    df["volatility_mid_price"] = df["volatility_mid_price"].fillna(method="bfill")

    # Encode venue and side
    df = pd.get_dummies(df, columns=["venue", "side"], drop_first=True)

    df["trade"] = df["trade"].map({False: 0, True: 1})
    df["action"] = df["action"].map({"A": 0, "D": 1, "U": 2})

    df["bid_size"] = np.log(df["bid_size"] + 1)
    df["ask_size"] = np.log(df["ask_size"] + 1)

    # Calculate mean and standard deviation for standardization
    price_mean = df["price"].mean()
    price_std = df["price"].std()
    bid_mean = df["bid"].mean()
    bid_std = df["bid"].std()
    ask_mean = df["ask"].mean()
    ask_std = df["ask"].std()

    # Apply z-score normalization
    df["price"] = (df["price"] - price_mean) / price_std
    df["bid"] = (df["bid"] - bid_mean) / bid_std
    df["ask"] = (df["ask"] - ask_mean) / ask_std

    tensor_list = []
    # Group by 'obs_id'
    for obs_id, group in df.groupby("obs_id"):
        # Drop 'obs_id' column if it's not needed
        features = group.drop(columns=["obs_id"])

        matrix = np.array(features.values, dtype=np.float32)

        # Append the Tensor to the tensor list
        tensor_list.append(matrix)

    df = pd.DataFrame({"column 1": tensor_list})

    return df
