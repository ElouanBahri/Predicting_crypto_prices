{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import xgboost as xgb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from modules.utils import filter_data_by_year_month, create_features_from_past, create_X_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('/Users/elouan/Repo Github ElouanBahri/Predicting_crypto_prices/Historical Prices for BTCUSDT')\n",
    "YEARS = [2019,2021,2022,2023,2024,2025]\n",
    "\n",
    "Data = filter_data_by_year_month(X, YEARS)\n",
    "\n",
    "Data1 = create_features_from_past(Data,['close', 'open', 'high', 'low', 'volume'], 8)\n",
    "\n",
    "X,y = create_X_y(Data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (141746, 40) (141746,)\n",
      "Testing set: (35437, 40) (35437,)\n"
     ]
    }
   ],
   "source": [
    "# Assuming X and y are your features and target arrays\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Print shapes to confirm\n",
    "print(\"Training set:\", X_train.shape, y_train.shape)\n",
    "\n",
    "print(\"Testing set:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "             importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "             learning_rate=0.1, max_bin=256, max_cat_to_onehot=4,\n",
       "             max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "             missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100, n_jobs=0,\n",
       "             num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=42,\n",
       "             reg_alpha=0, reg_lambda=1, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "             importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "             learning_rate=0.1, max_bin=256, max_cat_to_onehot=4,\n",
       "             max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "             missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100, n_jobs=0,\n",
       "             num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=42,\n",
       "             reg_alpha=0, reg_lambda=1, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "             importance_type=None, interaction_constraints='',\n",
       "             learning_rate=0.1, max_bin=256, max_cat_to_onehot=4,\n",
       "             max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "             missing=nan, monotone_constraints='()', n_estimators=100, n_jobs=0,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=42,\n",
       "             reg_alpha=0, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Initialize the XGBRegressor\n",
    "model = XGBRegressor(\n",
    "    n_estimators=100,       # Number of trees (boosting rounds)\n",
    "    max_depth=6,            # Maximum depth of each tree\n",
    "    learning_rate=0.1,      # Step size shrinkage\n",
    "    random_state=42         # Seed for reproducibility\n",
    ")\n",
    "\n",
    "# Fit the model to training data\n",
    "model.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MAE: 84.42158872804862\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate with MAE\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Validation MAE: {mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model('../models/xgboost_model_5(8).json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'objective': 'reg:squarederror', 'base_score': 0.5, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 1, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'gamma': 0, 'gpu_id': -1, 'grow_policy': 'depthwise', 'importance_type': None, 'interaction_constraints': '', 'learning_rate': 0.1, 'max_bin': 256, 'max_cat_to_onehot': 4, 'max_delta_step': 0, 'max_depth': 6, 'max_leaves': 0, 'min_child_weight': 1, 'missing': nan, 'monotone_constraints': '()', 'n_estimators': 100, 'n_jobs': 0, 'num_parallel_tree': 1, 'predictor': 'auto', 'random_state': 42, 'reg_alpha': 0, 'reg_lambda': 1, 'sampling_method': 'uniform', 'scale_pos_weight': 1, 'subsample': 1, 'tree_method': 'auto', 'validate_parameters': 1, 'verbosity': None}\n"
     ]
    }
   ],
   "source": [
    "model = XGBRegressor()\n",
    "model.load_model('../models/xgboost_model_4.json')\n",
    "print(model.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomized Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'learning_rate': 0.1,          # Reasonable default learning rate\n",
    "    'max_depth': 6,                # Medium tree depth\n",
    "    'n_estimators': 100,           # Default number of trees\n",
    "    'min_child_weight': 1,         # Default for child weight\n",
    "    'subsample': 0.8,              # Common default for subsampling\n",
    "    'colsample_bytree': 0.8,       # Subsampling for features\n",
    "    'reg_alpha': 0,                # No L1 regularization by default\n",
    "    'reg_lambda': 1,               # Default L2 regularization\n",
    "    'random_state': 42,            # For reproducibility\n",
    "    'tree_method': 'auto',         # Choose best tree method\n",
    "    'n_jobs': -1                   # Use all cores\n",
    "}\n",
    "\n",
    "                  # L2 regularization\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],         # Number of boosting rounds\n",
    "    'max_depth': [4, 6, 8],                   # Maximum depth of a tree\n",
    "    'learning_rate': [0.05, 0.1, 0.2],        # Learning rate (shrinkage)\n",
    "    'subsample': [0.8, 1.0],                  # Subsample ratio of the training set\n",
    "    'colsample_bytree': [0.8, 1.0],        # Subsample ratio of columns per tree\n",
    "    'gamma': [0, 0.1, 0.2],                   # Minimum loss reduction required to split\n",
    "    'min_child_weight': [1, 3, 5],            # Minimum sum of weights of all observations in a child\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=4, min_child_weight=5, n_estimators=200, subsample=0.8;, score=-105.641 total time= 1.6min\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=4, min_child_weight=5, n_estimators=200, subsample=0.8;, score=-106.826 total time= 1.7min\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=4, min_child_weight=5, n_estimators=200, subsample=0.8;, score=-106.480 total time= 1.7min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.05, max_depth=8, min_child_weight=3, n_estimators=100, subsample=1.0;, score=-226.149 total time= 2.1min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.05, max_depth=8, min_child_weight=3, n_estimators=100, subsample=1.0;, score=-226.159 total time= 2.1min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=4, min_child_weight=3, n_estimators=200, subsample=1.0;, score=-102.605 total time= 2.2min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=4, min_child_weight=3, n_estimators=200, subsample=1.0;, score=-103.125 total time= 2.2min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=4, min_child_weight=3, n_estimators=200, subsample=1.0;, score=-104.091 total time= 2.2min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=8, min_child_weight=5, n_estimators=50, subsample=1.0;, score=-2800.065 total time=  59.2s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.05, max_depth=8, min_child_weight=3, n_estimators=100, subsample=1.0;, score=-224.293 total time= 2.1min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=8, min_child_weight=5, n_estimators=100, subsample=0.8;, score=-90.420 total time= 2.0min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=8, min_child_weight=5, n_estimators=100, subsample=0.8;, score=-90.676 total time= 2.0min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=8, min_child_weight=5, n_estimators=100, subsample=0.8;, score=-89.751 total time= 2.0min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=8, min_child_weight=5, n_estimators=50, subsample=1.0;, score=-2798.446 total time=  59.6s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.2, max_depth=4, min_child_weight=3, n_estimators=50, subsample=1.0;, score=-142.592 total time=  26.4s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.2, max_depth=4, min_child_weight=3, n_estimators=50, subsample=1.0;, score=-142.716 total time=  27.4s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.2, max_depth=4, min_child_weight=3, n_estimators=50, subsample=1.0;, score=-141.407 total time=  27.5s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=8, min_child_weight=5, n_estimators=50, subsample=1.0;, score=-2783.659 total time= 1.0min\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.2, max_depth=8, min_child_weight=5, n_estimators=200, subsample=1.0;, score=-90.293 total time= 3.6min\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.2, max_depth=8, min_child_weight=5, n_estimators=200, subsample=1.0;, score=-90.373 total time= 3.7min\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.2, max_depth=8, min_child_weight=5, n_estimators=200, subsample=1.0;, score=-89.488 total time= 3.7min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.2, max_depth=8, min_child_weight=5, n_estimators=50, subsample=1.0;, score=-89.858 total time= 1.1min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.2, max_depth=8, min_child_weight=5, n_estimators=50, subsample=1.0;, score=-90.095 total time= 1.1min\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.2, max_depth=4, min_child_weight=3, n_estimators=200, subsample=0.8;, score=-111.229 total time= 1.6min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=6, min_child_weight=3, n_estimators=50, subsample=1.0;, score=-200.669 total time=  46.9s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.2, max_depth=4, min_child_weight=3, n_estimators=200, subsample=0.8;, score=-110.597 total time= 1.6min\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.2, max_depth=4, min_child_weight=3, n_estimators=200, subsample=0.8;, score=-108.811 total time= 1.6min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.2, max_depth=8, min_child_weight=5, n_estimators=50, subsample=1.0;, score=-89.046 total time= 1.0min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=6, min_child_weight=3, n_estimators=50, subsample=1.0;, score=-200.455 total time=  46.1s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=6, min_child_weight=3, n_estimators=50, subsample=1.0;, score=-198.404 total time=  46.9s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.8;, score=-107.331 total time=  55.3s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.8;, score=-107.439 total time=  55.9s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.8;, score=-106.583 total time=  54.5s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=100, subsample=1.0;, score=-106.392 total time= 1.0min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=100, subsample=1.0;, score=-106.483 total time= 1.0min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=100, subsample=1.0;, score=-106.839 total time= 1.0min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=4, min_child_weight=5, n_estimators=50, subsample=0.8;, score=-210.052 total time=  26.1s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=4, min_child_weight=5, n_estimators=50, subsample=0.8;, score=-209.579 total time=  26.4s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=4, min_child_weight=5, n_estimators=50, subsample=0.8;, score=-208.075 total time=  25.9s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=8, min_child_weight=3, n_estimators=100, subsample=0.8;, score=-90.588 total time= 1.7min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=8, min_child_weight=3, n_estimators=100, subsample=0.8;, score=-90.808 total time= 1.7min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=8, min_child_weight=3, n_estimators=100, subsample=0.8;, score=-89.829 total time= 1.7min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.8;, score=-201.065 total time=  40.2s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=100, subsample=1.0;, score=-85.355 total time= 1.2min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.8;, score=-200.549 total time=  40.1s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=100, subsample=1.0;, score=-85.539 total time= 1.2min\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=6, min_child_weight=5, n_estimators=100, subsample=1.0;, score=-84.735 total time= 1.2min\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=6, min_child_weight=5, n_estimators=50, subsample=0.8;, score=-2800.956 total time=  32.1s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.8;, score=-199.022 total time=  39.6s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.2, max_depth=8, min_child_weight=3, n_estimators=200, subsample=0.8;, score=-90.790 total time= 2.8min\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=6, min_child_weight=5, n_estimators=50, subsample=0.8;, score=-2798.644 total time=  31.6s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=6, min_child_weight=5, n_estimators=50, subsample=0.8;, score=-2784.111 total time=  32.1s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.2, max_depth=8, min_child_weight=3, n_estimators=200, subsample=0.8;, score=-91.043 total time= 2.8min\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.2, max_depth=8, min_child_weight=3, n_estimators=200, subsample=0.8;, score=-89.943 total time= 2.8min\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.2, max_depth=8, min_child_weight=1, n_estimators=50, subsample=1.0;, score=-90.297 total time=  40.4s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.2, max_depth=8, min_child_weight=1, n_estimators=50, subsample=1.0;, score=-89.877 total time=  40.4s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.2, max_depth=8, min_child_weight=1, n_estimators=50, subsample=1.0;, score=-88.937 total time=  37.2s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=8, min_child_weight=3, n_estimators=100, subsample=1.0;, score=-90.042 total time= 1.4min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=8, min_child_weight=3, n_estimators=100, subsample=1.0;, score=-89.777 total time= 1.4min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=8, min_child_weight=3, n_estimators=100, subsample=1.0;, score=-88.730 total time= 1.3min\n",
      "Best Parameters: {'subsample': 1.0, 'n_estimators': 100, 'min_child_weight': 5, 'max_depth': 6, 'learning_rate': 0.1, 'gamma': 0.2, 'colsample_bytree': 0.8}\n",
      "Best MAE: 85.20949696494891\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Base model\n",
    "xgb_model = XGBRegressor(**base_params)\n",
    "\n",
    "# Randomized search\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=20,                                # Reduced number of samples\n",
    "    scoring='neg_mean_absolute_error',        # MAE as the scoring metric\n",
    "    cv=3,                                     # 3-fold cross-validation\n",
    "    verbose=3,                                # Moderate verbosity\n",
    "    random_state=42,                          # Reproducibility\n",
    "    n_jobs=-1                                 # Use all cores\n",
    ")\n",
    "\n",
    "# Fit the randomized search\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Display the best parameters and score\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "print(\"Best MAE:\", -random_search.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridResearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1458 candidates, totalling 4374 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, subsample=0.8;, score=-13245.513 total time=  28.7s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, subsample=0.8;, score=-13323.571 total time=  29.1s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, subsample=0.8;, score=-13315.523 total time=  29.2s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, subsample=1.0;, score=-13321.818 total time=  31.4s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, subsample=1.0;, score=-13313.120 total time=  31.7s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, subsample=1.0;, score=-13244.676 total time=  31.7s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=200, subsample=0.8;, score=-4922.100 total time=  59.4s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=200, subsample=0.8;, score=-4924.248 total time=  59.6s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 29\u001b[0m\n\u001b[1;32m     19\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[1;32m     20\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mxgb_model,\n\u001b[1;32m     21\u001b[0m     param_grid\u001b[38;5;241m=\u001b[39mparam_grid,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m                           \u001b[38;5;66;03m# Use all CPU cores for parallelism\u001b[39;00m\n\u001b[1;32m     26\u001b[0m )\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Fit the grid search\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Output best parameters and best score\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_search\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[0;32m~/anaconda3/envs/Predicting_crypto/lib/python3.11/site-packages/sklearn/model_selection/_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    870\u001b[0m     )\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 874\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/Predicting_crypto/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1387\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1388\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Predicting_crypto/lib/python3.11/site-packages/sklearn/model_selection/_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    814\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    818\u001b[0m         )\n\u001b[1;32m    819\u001b[0m     )\n\u001b[0;32m--> 821\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/Predicting_crypto/lib/python3.11/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Predicting_crypto/lib/python3.11/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Predicting_crypto/lib/python3.11/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/Predicting_crypto/lib/python3.11/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Initialize the XGBRegressor\n",
    "xgb_model = XGBRegressor(\n",
    "    random_state=42,\n",
    "    tree_method='auto'  # Use 'gpu_hist' for GPU acceleration if GPU is available\n",
    ")\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 400],           # Number of boosting rounds\n",
    "    'max_depth': [3, 5, 7],                   # Maximum depth of a tree\n",
    "    'learning_rate': [0.01, 0.1, 0.3],        # Learning rate (shrinkage)\n",
    "    'subsample': [0.8, 1.0],                  # Subsample ratio of the training set\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],      # Subsample ratio of columns per tree\n",
    "    'gamma': [0, 0.1, 0.2],                   # Minimum loss reduction required to split\n",
    "    'min_child_weight': [1, 3, 5],            # Minimum sum of weights of all observations in a child\n",
    "}\n",
    "\n",
    "# Perform grid search with GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='neg_mean_absolute_error',  # Scoring metric: negative MAE\n",
    "    cv=3,                               # 3-fold cross-validation\n",
    "    verbose=3,                          # Display progress\n",
    "    n_jobs=-1                           # Use all CPU cores for parallelism\n",
    ")\n",
    "\n",
    "# Fit the grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Output best parameters and best score\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best MAE:\", -grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "challenge_ENS_env_QRT_2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
